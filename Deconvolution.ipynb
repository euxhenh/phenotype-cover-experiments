{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11dc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import src.load as load\n",
    "import jsbeautifier\n",
    "from src._operations import group_by\n",
    "from src.deconvolution import Deconvolution\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import pearsonr, entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.utils.validation import column_or_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d882a1",
   "metadata": {},
   "source": [
    "<h2>Data</h2>\n",
    "\n",
    "Three datasets were used in this study.\n",
    "\n",
    "1. **Idiopathic Pulmonary Fibrosis (IPF)**: 96,301 cells and 4,443 highly variable genes. (https://www.science.org/doi/10.1126/sciadv.aba1983)\n",
    "2. **Mouse Cortex (MC)**: 3,005 cells and 20,006 genes. After filtering genes expressed in at least 10 cells, we are left with 16,484 genes. (https://www.science.org/doi/10.1126/science.aaa1934)\n",
    "3. **Human Cell Atlas (HCA)**: 84,363 cells and 2,968 highly variable genes. (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02210-0)\n",
    "\n",
    "These datasets can be downloaded as .h5ad files from https://drive.google.com/drive/folders/1fLt3QGI2XFIz-4ZjOwk9poFpmqq1Zcgt?usp=sharing.\n",
    "\n",
    "Since IPF and HCA are large, we only work with highly variable genes to reduce the runtime of the methods.\n",
    "The IPF h5ad file contains highly variable genes only, so we only need to set `high_var` to `True` for HCA.\n",
    "`filter_genes` will be set to True for both MC and HCA.\n",
    "\n",
    "Only for scGeneFit we also set `high_var=True` for MC. Without it, the algorithm will take too long to run across all random seeds and coverage factors.\n",
    "\n",
    "The default method for selecting highly variable genes in Scanpy requires the data to be log-transformed (https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.highly_variable_genes.html). However, deconvolution works best in linear space. For this reason, high variable genes for HCA have been saved into `data/he-hv.txt` and loaded from there to simply the code.\n",
    "\n",
    "Finally, we remove all classes with less than 50 cells. This leads to 33 classes for IPF and 75 classes for HCA (tissue/cell type pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc585f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path('HCA') # choose from IPF, HCA, MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c9ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 unique cell types.\n",
      "adata.shape=(3005, 20006)\n",
      "Removed low count classes.\n",
      "adata.shape=(3005, 5034)\n",
      "7 celltype combinations.\n",
      "Range: 0.0 3107.6062\n"
     ]
    }
   ],
   "source": [
    "root = 'data' / dataset\n",
    "os.makedirs(root / 'images', exist_ok=True)\n",
    "\n",
    "# We don't log for cibersort\n",
    "adata, key = load.dataset(\n",
    "    str(dataset),\n",
    "    filter_genes=False if str(dataset) == 'IPF' else True,\n",
    "    normalize=True,\n",
    "    high_var=True if str(dataset) == 'HCA' else False,\n",
    "    #high_var=True # set to True for MC is running scGeneFit\n",
    ")\n",
    "adata = load.remove_low_count_ct(adata, key, 50)\n",
    "print(\"Range:\", adata.X.min(), adata.X.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9388105",
   "metadata": {},
   "source": [
    "Split the data into train and test. Form a signature matrix using train data and form a pseudo-mixture using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9107bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(adata, key, *, rs=42, verbose=False):\n",
    "    x_train, x_test = tts(adata, random_state=rs, stratify=adata.obs[key], train_size=0.5)\n",
    "    # Form the signature matrix by averaging per phenotype\n",
    "    signature = np.asarray(group_by(x_train.X, x_train.obs[key]))\n",
    "    mixture = np.array(x_test.X.mean(axis=0)).flatten()\n",
    "    _, ground_truth = np.unique(x_test.obs[key], return_counts=True)\n",
    "    ground_truth = ground_truth.astype(float) / x_test.shape[0]\n",
    "    if verbose:\n",
    "        print(f\"Formed signature matrix with shape {signature.shape}\")\n",
    "        print(f\"Max value in the signature matrix: {signature.max()}\")\n",
    "        print(f\"Formed mixture with shape {mixture.shape}\")\n",
    "    del x_train\n",
    "    del x_test\n",
    "    gc.collect()\n",
    "    return signature, mixture, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2dbcf",
   "metadata": {},
   "source": [
    "Run deconvolution using $\\nu$-SVR (CIBERSORT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93ddfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(\n",
    "        signature,\n",
    "        mixture,\n",
    "        *,\n",
    "        dict_key,\n",
    "        ground_truth,\n",
    "        feature_selector=None,\n",
    "        selected=None,\n",
    "        json_path=None,\n",
    "        report=None,\n",
    "    ):\n",
    "    \"\"\"Run CIBERSORT using the given signature matrix\n",
    "    and mixture by using only features returned by\n",
    "    feature selector.\n",
    "    \"\"\"\n",
    "    if selected is None:\n",
    "        assert feature_selector is not None\n",
    "        selected = feature_selector.get_support(indices=True)\n",
    "    dv = Deconvolution(verbose=False)\n",
    "    deconvolved = dv.fit_predict(\n",
    "        signature.T[selected],\n",
    "        column_or_1d(mixture)[selected])\n",
    "    \n",
    "    if report is None:\n",
    "        report = {}\n",
    "    report[dict_key] = {}\n",
    "    report[dict_key]['n_features'] = len(selected)\n",
    "    report[dict_key]['phenotypes'] = signature.shape[0]\n",
    "    report[dict_key]['n_features_in'] = signature.shape[1]\n",
    "    report[dict_key]['JS'] = jensenshannon(deconvolved, ground_truth)\n",
    "    report[dict_key]['entropy'] = entropy(deconvolved, ground_truth)\n",
    "    report[dict_key]['pearson'] = pearsonr(deconvolved, ground_truth)[0]\n",
    "    report[dict_key]['deconvolution'] = deconvolved.tolist()\n",
    "    if isinstance(selected, np.ndarray):\n",
    "        selected = selected.tolist()\n",
    "    report[dict_key]['solution'] = selected\n",
    "    # Dump json\n",
    "    options = jsbeautifier.default_options()\n",
    "    options.indent_size = 4\n",
    "    beau_report = jsbeautifier.beautify(json.dumps(report), options)\n",
    "\n",
    "    if json_path is not None:\n",
    "        with open(json_path, \"w\") as f:\n",
    "            f.write(beau_report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def load_rep(path_to_json):\n",
    "    with open(path_to_json, \"r\") as f:\n",
    "        __report = json.load(f)\n",
    "    return __report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da70b3",
   "metadata": {},
   "source": [
    "<h2>Run deconvolution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12990d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_filename = 'report.json'\n",
    "deconv_filename = 'deconv.json'\n",
    "\n",
    "base_dirs = [\n",
    "    'GreedyCover',\n",
    "    'DT',\n",
    "    'TopDE',\n",
    "    'ReliefF',\n",
    "    'Fval',\n",
    "    'MI',\n",
    "    'mRMR',\n",
    "    'CrossEntropy',\n",
    "    'RankCorr',\n",
    "    'scGeneFit',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2716d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every random seed\n",
    "for rs in range(42, 47):\n",
    "    signature, mixture, ground_truth = get_signature(adata, key, rs=rs)\n",
    "    sub_root = 'data' / dataset / 'RS' / f'rs{rs}'\n",
    "    bd = [sub_root / m for m in base_dirs]\n",
    "    \n",
    "    # For every method\n",
    "    for rd in tqdm(bd):\n",
    "        f_report = load_rep(rd / report_filename)\n",
    "\n",
    "        report = {}\n",
    "        # For every coverage factor\n",
    "        for cov in tqdm(f_report):\n",
    "            _ = deconv(\n",
    "                signature,\n",
    "                mixture,\n",
    "                dict_key=cov,\n",
    "                ground_truth=ground_truth,\n",
    "                json_path=rd / deconv_filename,\n",
    "                selected=f_report[cov]['solution'],\n",
    "                report=report,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
