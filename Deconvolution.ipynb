{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11dc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import src.load as load\n",
    "import jsbeautifier\n",
    "from src._operations import group_by\n",
    "from src.deconvolution import Deconvolution\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import pearsonr, entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.utils.validation import column_or_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75aa0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path('IPF')\n",
    "root = 'data' / dataset\n",
    "os.makedirs(root, exist_ok=True)\n",
    "os.makedirs(root / 'images/png', exist_ok=True)\n",
    "os.makedirs(root / 'images/svg', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d882a1",
   "metadata": {},
   "source": [
    "<h2>Load adata</h2>\n",
    "Deconvolution works best on linear space so we do not log-transform the data.\n",
    "`filter_genes`, `normalize` are set to True for all datasets.\n",
    "`high_var` is set to True for HCA for run-time efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297eb7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata.shape=(96301, 4443)\n",
      "Removed low count classes.\n",
      "adata.shape=(96196, 4443)\n",
      "33 label combinations.\n"
     ]
    }
   ],
   "source": [
    "adata, key = load.dataset(\n",
    "    str(dataset),\n",
    "    filter_genes=False, # set to true for MC, HCA, false for IPF\n",
    "    normalize=True,\n",
    "    high_var=False, # set to true for HCA, false for MC, IPF\n",
    "    log=False, # don't log for cibersort\n",
    "    scale=False,\n",
    ")\n",
    "adata = load.remove_low_count_ct(adata, key, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9388105",
   "metadata": {},
   "source": [
    "Split the data into train and test. Form a signature matrix using train data and form a pseudo-mixture using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9107bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(adata, key, *, rs=42, verbose=False):\n",
    "    x_train, x_test = tts(adata, random_state=rs, stratify=adata.obs[key], train_size=0.5)\n",
    "    # Form the signature matrix by averaging per phenotype\n",
    "    signature = np.asarray(group_by(x_train.X, x_train.obs[key]))\n",
    "    mixture = np.array(x_test.X.mean(axis=0)).flatten()\n",
    "    _, ground_truth = np.unique(x_test.obs[key], return_counts=True)\n",
    "    ground_truth = ground_truth.astype(float) / x_test.shape[0]\n",
    "    if verbose:\n",
    "        print(f\"Formed signature matrix with shape {signature.shape}\")\n",
    "        print(f\"Max value in the signature matrix: {signature.max()}\")\n",
    "        print(f\"Formed mixture with shape {mixture.shape}\")\n",
    "    del x_train\n",
    "    del x_test\n",
    "    gc.collect()\n",
    "    return signature, mixture, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2dbcf",
   "metadata": {},
   "source": [
    "Run deconvolution using nu_SVR (CIBERSORT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93ddfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(\n",
    "        signature,\n",
    "        mixture,\n",
    "        *,\n",
    "        dict_key,\n",
    "        ground_truth,\n",
    "        feature_selector=None,\n",
    "        selected=None,\n",
    "        json_path=None,\n",
    "        report=None,\n",
    "    ):\n",
    "    \"\"\"Run CIBERSORT using the given signature matrix\n",
    "    and mixture by using only features returned by\n",
    "    feature selector.\n",
    "    \"\"\"\n",
    "    if selected is None:\n",
    "        assert feature_selector is not None\n",
    "        selected = feature_selector.get_support(indices=True)\n",
    "    dv = Deconvolution(verbose=False)\n",
    "    deconvolved = dv.fit_predict(\n",
    "        signature.T[selected],\n",
    "        column_or_1d(mixture)[selected])\n",
    "    \n",
    "    if report is None:\n",
    "        report = {}\n",
    "    report[dict_key] = {}\n",
    "    report[dict_key]['n_features'] = len(selected)\n",
    "    report[dict_key]['phenotypes'] = signature.shape[0]\n",
    "    report[dict_key]['n_features_in'] = signature.shape[1]\n",
    "    report[dict_key]['JS'] = jensenshannon(deconvolved, ground_truth)\n",
    "    report[dict_key]['entropy'] = entropy(deconvolved, ground_truth)\n",
    "    report[dict_key]['pearson'] = pearsonr(deconvolved, ground_truth)[0]\n",
    "    report[dict_key]['deconvolution'] = deconvolved.tolist()\n",
    "    if isinstance(selected, np.ndarray):\n",
    "        selected = selected.tolist()\n",
    "    report[dict_key]['solution'] = selected\n",
    "    # Dump json\n",
    "    options = jsbeautifier.default_options()\n",
    "    options.indent_size = 4\n",
    "    beau_report = jsbeautifier.beautify(json.dumps(report), options)\n",
    "\n",
    "    if json_path is not None:\n",
    "        with open(json_path, \"w\") as f:\n",
    "            f.write(beau_report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def load_rep(path_to_json):\n",
    "    with open(path_to_json, \"r\") as f:\n",
    "        __report = json.load(f)\n",
    "    return __report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da70b3",
   "metadata": {},
   "source": [
    "<h2>Read reports and run deconvolution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12990d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_filename = 'report.json'\n",
    "deconv_filename = 'deconv.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs = [\n",
    "#     'GreedyCover',\n",
    "#     'DT',\n",
    "#     'TopDE',\n",
    "#     'ReliefF',\n",
    "    'scGeneFit',\n",
    "#     'Fval',\n",
    "#     'MI',\n",
    "#     'mRMR',\n",
    "#     'CrossEntropy',\n",
    "]\n",
    "\n",
    "# For every random seed\n",
    "for rs in range(44, 47):\n",
    "    signature, mixture, ground_truth = get_signature(adata, key, rs=rs)\n",
    "    sub_root = 'data' / dataset / 'RS' / f'rs{rs}'\n",
    "    bd = [sub_root / m for m in base_dirs]\n",
    "    \n",
    "    # For every method\n",
    "    for rd in tqdm(bd):\n",
    "        f_report = load_rep(rd / report_filename)\n",
    "\n",
    "        report = {}\n",
    "        # For every coverage factor\n",
    "        for cov in tqdm(f_report):\n",
    "            _ = deconv(\n",
    "                signature,\n",
    "                mixture,\n",
    "                dict_key=cov,\n",
    "                ground_truth=ground_truth,\n",
    "                json_path=rd / deconv_filename,\n",
    "                selected=f_report[cov]['solution'],\n",
    "                report=report,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88844a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
