{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8ca7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import src.load as load\n",
    "from src.utils.experiment import (\n",
    "    fit_and_dump_GCS,\n",
    "    fit_and_dump_DT,\n",
    "    fit_and_dump_topDE,\n",
    "    fit_and_dump_ReliefF,\n",
    "    fit_and_dump_scGeneFit,\n",
    "    fit_and_dump_Fval,\n",
    "    fit_and_dump_MI,\n",
    "    fit_and_dump_mRMR,\n",
    "    fit_and_dump_CEM,\n",
    "    fit_and_dump_RankCorr,\n",
    "    get_feat_list,\n",
    ")\n",
    "\n",
    "import os, gc\n",
    "import anndata\n",
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e471b",
   "metadata": {},
   "source": [
    "<h3>Data</h3>\n",
    "\n",
    "Three datasets were used in this study.\n",
    "\n",
    "1. **Idiopathic Pulmonary Fibrosis (IPF)**: 96,301 cells and 4,443 highly variable genes. (https://www.science.org/doi/10.1126/sciadv.aba1983)\n",
    "2. **Mouse Cortex (MC)**: 3,005 cells and 20,006 genes. After filtering genes expressed in at least 10 cells, we are left with 16,484 genes. (https://www.science.org/doi/10.1126/science.aaa1934)\n",
    "3. **Human Cell Atlas (HCA)**: 84,363 cells and 2,968 highly variable genes. (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02210-0)\n",
    "\n",
    "These datasets can be downloaded as .h5ad files from https://drive.google.com/drive/folders/1fLt3QGI2XFIz-4ZjOwk9poFpmqq1Zcgt?usp=sharing.\n",
    "\n",
    "Since IPF and HCA are large, we only work with highly variable genes to reduce the runtime of the methods.\n",
    "The IPF h5ad file contains highly variable genes only, so we only need to set `high_var` to `True` for HCA.\n",
    "`filter_genes` will be set to True for both MC and HCA.\n",
    "\n",
    "Only for scGeneFit we also set `high_var=True` for MC. Without it, the algorithm will take too long to run across all random seeds and coverage factors.\n",
    "\n",
    "All data is total count normalized (`normalize = True`), log1p transformed (`log = True`) and scaled to unit variance and zero-mean (`scale = True`). scGeneFit performed poorly when data was scaled, so we skip scaling for this method. Scanpy is performing the preprocessing in the backend.\n",
    "\n",
    "Finally, we remove all classes with less than 50 cells. This leads to 33 classes for IPF and 75 classes for HCA (tissue/cell type pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7060f2e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 unique cell types.\n",
      "adata.shape=(3005, 20006)\n",
      "Removed low count classes.\n",
      "adata.shape=(3005, 16484)\n",
      "7 celltype combinations.\n",
      "Range: -8.1035595 10.0\n"
     ]
    }
   ],
   "source": [
    "# Choose dataset\n",
    "dataset = Path('IPF')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "root = 'data' / dataset\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "filter_genes = False if str(dataset) == 'IPF' else True\n",
    "normalize = True\n",
    "log = True\n",
    "scale = True # Set to False if testing scGeneFit\n",
    "high_var = True if str(dataset) == 'HCA' else False\n",
    "#high_var = True # True for MC if running scGeneFit\n",
    "\n",
    "# Load data\n",
    "adata, key = load.dataset(\n",
    "    str(dataset),\n",
    "    normalize=normalize,\n",
    "    log=log,\n",
    "    scale=scale,\n",
    "    high_var=high_var,\n",
    "    filter_genes=filter_genes,\n",
    ")\n",
    "adata = load.remove_low_count_ct(adata, key, 50)\n",
    "print(\"Range:\", adata.X.min(), adata.X.max())\n",
    "\n",
    "# sparse matrices will raise an error for some methods\n",
    "if not scale and sp.issparse(adata.X):\n",
    "    __mat = np.array(adata.X.todense())\n",
    "    __ad = anndata.AnnData(__mat)\n",
    "    __ad.obs = adata.obs\n",
    "    adata = __ad\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5cc650",
   "metadata": {},
   "source": [
    "<h2>GVars</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee57144",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = 'report.json'\n",
    "feature_importances_filename = 'feature_importances_.txt'\n",
    "\n",
    "params = {\n",
    "    'n_train': adata.shape[0] // 2,\n",
    "    'n_features_in': adata.shape[1],\n",
    "    'n_classes': np.unique(adata.obs[key]).size,\n",
    "    'filter_genes': filter_genes,\n",
    "    'normalize': normalize,\n",
    "    'log': log,\n",
    "    'scale': scale,\n",
    "    'high_var': high_var,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db5d8f",
   "metadata": {},
   "source": [
    "Select methods to fit. GreedyCover must be run first in order to determine the number of features to select using other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e28371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fit = [\n",
    "    'GreedyCover',\n",
    "    'DT',\n",
    "    'TopDE',\n",
    "    'ReliefF',\n",
    "    'Fval',\n",
    "    'MI',\n",
    "    'mRMR',\n",
    "    'CrossEntropy',\n",
    "    'RankCorr',\n",
    "    #'scGeneFit', # run this separately without scaled data for better results\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec92c7e",
   "metadata": {},
   "source": [
    "`TopDE`, `CrossEntropy`, and `RankCorr` may require some manual tuning of the parameters since the number of features to select can not be fixed in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf357a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = np.arange(42, 47)\n",
    "rs_root = 'data' / dataset / 'RS'\n",
    "# set root based on a fixed greedy cover run\n",
    "greedy_root = rs_root / f'rs42' / 'GreedyCover' / json_filename\n",
    "\n",
    "for random_seed in tqdm(random_seeds):\n",
    "    x_train, x_test = tts(\n",
    "        adata, random_state=random_seed,\n",
    "        stratify=adata.obs[key], train_size=0.5)\n",
    "    params['n_train'] = x_train.shape[0]\n",
    "    gc.collect()\n",
    "    root = rs_root / f'rs{random_seed}'\n",
    "    \n",
    "    coverage_list = np.arange(1, 20).tolist()\n",
    "    kwargs = {\n",
    "        'root': root,\n",
    "        'data': x_train,\n",
    "        'key': key,\n",
    "        'extras': params,\n",
    "        'coverage_list': coverage_list,\n",
    "        'json_filename': json_filename,\n",
    "    }\n",
    "    if 'GreedyCover' in to_fit: fit_and_dump_GCS(**kwargs)\n",
    "        \n",
    "    # Reload coverage_list based on greedy root\n",
    "    # so that all methods have the same number of features\n",
    "    # selected across all runs.\n",
    "    coverage_list, max_features_list = get_feat_list(greedy_root)\n",
    "    kwargs['coverage_list'] = coverage_list\n",
    "    kwargs['max_features_list'] = max_features_list\n",
    "    \n",
    "    if 'DT' in to_fit: fit_and_dump_DT(**kwargs)\n",
    "    if 'TopDE' in to_fit: fit_and_dump_topDE(**kwargs)\n",
    "    if 'ReliefF' in to_fit: fit_and_dump_ReliefF(**kwargs)\n",
    "    if 'scGeneFit' in to_fit: fit_and_dump_scGeneFit(**kwargs)\n",
    "    if 'Fval' in to_fit: fit_and_dump_Fval(**kwargs)\n",
    "    if 'MI' in to_fit: fit_and_dump_MI(**kwargs)\n",
    "    if 'mRMR' in to_fit: fit_and_dump_mRMR(**kwargs)\n",
    "    if 'RankCorr' in to_fit: fit_and_dump_RankCorr(\n",
    "        **kwargs, lamb_list=(np.arange(1, 16) / 4.5).tolist())\n",
    "    if 'CEM' in to_fit:\n",
    "        # separate coverage list for CEM since n features varies a lot\n",
    "        coverage_list = np.arange(10, 15)\n",
    "        kwargs['smoothing_parameter'] = None\n",
    "        kwargs['coverage_list'] = coverage_list.tolist()\n",
    "        fit_and_dump_CEM(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
